{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_with_semantic_and_tech_attributes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPj+9nzbt8W+7vEe7cLZegn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-mustapha/PROJETS-JEDHA/blob/main/model_with_semantic_and_tech_attributes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "DBegHreDwgl3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcKoiuhhs6vy",
        "outputId": "a7518f66-09ec-45e9-c88d-d4433b5ff826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/111_goldfinger/data_modeling')"
      ],
      "metadata": {
        "id": "znPpgB2bDtgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "jN2SYJbkD3br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.4\n",
        "!pip install sklearn\n",
        "!pip install missingpy\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "oBK-8VHxD8nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # to avoid deprecation warnings\n",
        "import sys\n",
        "\n",
        "\n",
        "#Graph libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#Preprocessing libraries\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import  OneHotEncoder, StandardScaler,LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#Model Selection\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
        "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "import sklearn.neighbors._base\n",
        "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
        "\n",
        "from missingpy import KNNImputer"
      ],
      "metadata": {
        "id": "L-PyO7PbE0_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/111_goldfinger/data_modeling/tech.csv')"
      ],
      "metadata": {
        "id": "kbfnbm9jFUbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample()"
      ],
      "metadata": {
        "id": "OKvFzhUjFZTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "YMv_NQoBFf71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample()"
      ],
      "metadata": {
        "id": "n1POFA4FvxSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Distribution plot**"
      ],
      "metadata": {
        "id": "WS4h2PHlv5ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [6, 2]\n",
        "%matplotlib inline\n",
        "\n",
        "# sample time series data\n",
        "df2 = df.copy()\n",
        "\n",
        "\n",
        "# create distplots\n",
        "for c in df2.columns:\n",
        "    plt.figure()             # <==================== here!\n",
        "    sns.distplot(df2[c])"
      ],
      "metadata": {
        "id": "uKYhtbWxFp3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plot pairwise relationships in the dataset**"
      ],
      "metadata": {
        "id": "UTObDmkNwQZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df,corner=True, diag_kind=\"kde\");"
      ],
      "metadata": {
        "id": "iUUGqqHTwY4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part II Preprocessing & model selection**"
      ],
      "metadata": {
        "id": "bX5FeIe3w8BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection of highly correlated features"
      ],
      "metadata": {
        "id": "qmrFgW6-xCzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting a matrix correlation of features\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(16,12))\n",
        "sns.heatmap(corr, annot=True, cmap='YlGnBu');"
      ],
      "metadata": {
        "id": "5CHmGWlkxKNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's identify most correlated features :\n",
        "correlations = corr.unstack().reset_index()\n",
        "correlations = correlations.rename(columns=dict(zip(correlations.columns, ['feature1', 'feature2', 'coeff'])))\n",
        "correlations['coeff'] = correlations['coeff'].apply(lambda x : abs(x))\n",
        "\n",
        "#Filtering features with a high correlation : \n",
        "top_correlations = correlations[(correlations.coeff !=1) &  (correlations.coeff > 0.8)].drop_duplicates(subset=['coeff'])\n",
        "top_correlations"
      ],
      "metadata": {
        "id": "qGRmI7YixgMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_delete = top_correlations.feature2.values\n",
        "to_delete"
      ],
      "metadata": {
        "id": "nsRbQJHMxmHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conclusion : let's drop the features which appear to be to much correlated with others !\n",
        "df.drop(columns=to_delete, inplace=True)"
      ],
      "metadata": {
        "id": "MEqGJ1hMxu7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipelines"
      ],
      "metadata": {
        "id": "HthV8Fv6x2At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "gVsqy9Fax_YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "nan_features = pd.Series(100* df.isnull().sum().sort_values(ascending=False) / df.shape[0]).to_frame()\n",
        "nan_features.rename(columns={0:'nan_percent'}, inplace=True)\n",
        "nan_features[nan_features.nan_percent > 0]"
      ],
      "metadata": {
        "id": "quaUxOd4yFjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2SQuUjvTyMbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_features[nan_features.nan_percent > 0].index"
      ],
      "metadata": {
        "id": "4z2lAQEHyRu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#delete records with nan values\n",
        "df = df.dropna(subset=nan_features[nan_features.nan_percent > 0].index)"
      ],
      "metadata": {
        "id": "XKcGPNIIyXZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "2RZQ4dUTycXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different tests have been done on the selection of features to set-up the best model. \n",
        "Finally, we discard from the analysis the tech spent and the majestic rank (based on top 1M of websites wordwide which cannot substitute the 'Authority Score').\n",
        "One of the improvement paths in the future could indeed be to test the integration of external data (ahref, semrush)."
      ],
      "metadata": {
        "id": "2axsURkryjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['content_len', 'title_len_char', 'h1_len', 'nb_h3', 'nb_links',\n",
        "       'has_canonical', 'is_top_ten', 'content_score', 'title_score',\n",
        "      'ref_sn']]"
      ],
      "metadata": {
        "id": "GnH7LRapypsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting features & target"
      ],
      "metadata": {
        "id": "O8SjA1TdyuFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'is_top_ten'\n",
        "\n",
        "X = df.loc[:, df.columns != target]\n",
        "Y = df.loc[:,target] \n",
        "\n",
        "Y = Y.apply(lambda x: float(x[1:]) if type(x)==str else x)\n",
        "\n",
        "#Split the data into a train set and test set \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "\n",
        "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
        "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_train = Y_train.tolist()\n",
        "Y_test = Y_test.tolist()\n",
        "print(\"...Numpy conversion to arrays Done !\")"
      ],
      "metadata": {
        "id": "24eT34jDy3nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically detect positions of numeric/categorical features :\n",
        "idx = 0\n",
        "numeric_features = []\n",
        "numeric_indices = []\n",
        "categorical_features = []\n",
        "categorical_indices = []\n",
        "for i,t in X.dtypes.iteritems():\n",
        "    if ('float' in str(t)) or ('int' in str(t)) :\n",
        "        numeric_features.append(i)\n",
        "        numeric_indices.append(idx)\n",
        "    else :\n",
        "        categorical_features.append(i)\n",
        "        categorical_indices.append(idx)\n",
        "\n",
        "    idx = idx + 1\n",
        "\n",
        "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
        "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)"
      ],
      "metadata": {
        "id": "h3hFm8r2zEvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from missingpy import KNNImputer\n",
        "imputer = KNNImputer()\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer',KNNImputer()),\n",
        "    ('scaler',StandardScaler()) \n",
        "])\n",
        "#StandardScaler()\n",
        "# Create pipeline for categorical features\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
        "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
        "    ])\n",
        "\n",
        "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_indices),\n",
        "        ('cat', categorical_transformer, categorical_indices)\n",
        "    ])\n",
        "\n",
        "# Preprocessings on train set\n",
        "print(\"Performing preprocessings on train set...\")\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "print('preprocessings on train set...Done.')\n",
        "\n",
        "\n",
        "# Preprocessings on test set\n",
        "print(\"Performing preprocessings on test set...\")\n",
        "X_test = preprocessor.transform(X_test) # Don't fit again !! The test set is used for validating decisions\n",
        "# we made based on the training set, therefore we can only apply transformations that were parametered using the training set.\n",
        "# Otherwise this creates what is called a leak from the test set which will introduce a bias in all your results.\n",
        "print('preprocessings on test set...Done.')"
      ],
      "metadata": {
        "id": "AJIXYsnwzSLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART II : Models fitting**"
      ],
      "metadata": {
        "id": "mCe9aOzyzbM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciate models\n",
        "\n",
        "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
        "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "gbm = xgb.XGBClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "et =  ExtraTreesClassifier()\n",
        "ada = AdaBoostClassifier()\n",
        "gb = GradientBoostingClassifier()\n",
        "lr = LogisticRegression()\n",
        "dt = DecisionTreeClassifier()\n",
        "lgb = lgb.LGBMClassifier()\n",
        "cb = CatBoostClassifier()"
      ],
      "metadata": {
        "id": "D5IO7Rnb0bSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import classification_report #pas utilisé\n",
        "classifier = []\n",
        "for model in [gbm, rf, et,  ada, gb, lr, dt,lgb, cb]:\n",
        "  \n",
        "\n",
        "  model.fit(X_train, Y_train)\n",
        "  Y_train_pred    = model.predict(X_train)\n",
        "  Y_test_pred     = model.predict(X_test)\n",
        "  score           = model.score(X_test, Y_test)\n",
        "  \n",
        "\n",
        "#for classification only\n",
        "\n",
        "  accuracy_train  = accuracy_score(Y_train, Y_train_pred)\n",
        "  accuracy_test   = accuracy_score(Y_test, Y_test_pred)\n",
        "  f1_score_train  = f1_score(Y_train, Y_train_pred)\n",
        "  f1_score_test   = f1_score(Y_test, Y_test_pred)\n",
        "\n",
        "  print()\n",
        "  print('model : ', model, ' - score : ', score, 'accuracy_train : ', accuracy_train, 'accuracy_test : ', accuracy_test)\n",
        "\n",
        "  \n",
        "\n",
        "  classifier.append({'classifier'     : model,\n",
        "                    'score'           : score,\n",
        "                    'accuracy_train'  : accuracy_train,\n",
        "                    'accuracy_test'   : accuracy_test,\n",
        "                    'f1_score_train'  : f1_score_train,\n",
        "                    'f1_score_test'   : f1_score_test\n",
        "                     }\n",
        "                    )"
      ],
      "metadata": {
        "id": "IjHPRj3s0tlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_scores = pd.DataFrame.from_dict(classifier)\n",
        "print(all_scores.sort_values(by='f1_score_test', ascending=False)['classifier'].values[:3])\n",
        "all_scores.sort_values(by='f1_score_test', ascending=False)"
      ],
      "metadata": {
        "id": "XOJrBc7601sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#There is a problem with the DataFrame display.\n",
        "# We'll consider best model as random forrest"
      ],
      "metadata": {
        "id": "LcBvsvGm1Esc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is it possible to lower over fitting on best model ?"
      ],
      "metadata": {
        "id": "--5kww4V1LzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score,GridSearchCV"
      ],
      "metadata": {
        "id": "2YkDmRw11Vgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier()\n",
        "param_grid = { \n",
        "    'n_estimators': [200,250, 300, 500],\n",
        "    'max_depth' : [15, 20],\n",
        "    # 'criterion' :['gini', 'entropy'],\n",
        "}\n",
        "m2 = GridSearchCV(estimator=model, param_grid=param_grid, cv= 5)\n",
        "m2.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Q0hSOaXO1bsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m2.best_params_"
      ],
      "metadata": {
        "id": "16pMbWpD1iJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(max_depth= 15, \n",
        "                               n_estimators= 300)\n",
        "classifier = []\n",
        "model.fit(X_train, Y_train)\n",
        "Y_train_pred    = model.predict(X_train)\n",
        "Y_test_pred     = model.predict(X_test)\n",
        "score           = model.score(X_test, Y_test)\n",
        "\n",
        "\n",
        "#for classification only\n",
        "\n",
        "accuracy_train  = accuracy_score(Y_train, Y_train_pred)\n",
        "accuracy_test   = accuracy_score(Y_test, Y_test_pred)\n",
        "f1_score_train  = f1_score(Y_train, Y_train_pred)\n",
        "f1_score_test   = f1_score(Y_test, Y_test_pred)\n",
        "\n",
        "print()\n",
        "print('model : ', model, ' - score : ', score, 'accuracy_train : ', accuracy_train, 'accuracy_test : ', accuracy_test)\n",
        "\n",
        "\n",
        "\n",
        "classifier.append({'classifier'     : model,\n",
        "                    'score'           : score,           \n",
        "                    'accuracy_test'   : accuracy_test,\n",
        "                    'f1_score_test'   : f1_score_test\n",
        "                     }\n",
        "                    )\n",
        "pd.DataFrame(data=classifier)"
      ],
      "metadata": {
        "id": "sOKljaTK1r1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feat_importances = pd.Series(model.feature_importances_ ,index=df.loc[:, df.columns != target].columns).to_frame()\n",
        "feat_importances.rename(columns={0: 'feature_importance'}, inplace=True)\n",
        "feat_importances.sort_values(by='feature_importance', ascending=False).mul(100)"
      ],
      "metadata": {
        "id": "dqJEyU4K17tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = feat_importances.sort_values(by='feature_importance', ascending=True).mul(100).round().plot(kind='barh', figsize=(12,8));\n",
        "for c in ax.containers:\n",
        "    ax.bar_label(c, label_type='center', color=\"white\")"
      ],
      "metadata": {
        "id": "MCaPWwiG2E9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}